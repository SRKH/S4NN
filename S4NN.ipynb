{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S4NN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTjwXbTyQXPD9qmrNzQq+a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Szy4SZVyznHR","colab_type":"text"},"source":["# S4NN\n","*The implementation of the supervied spiking neural network named S4NN presented in  \"Temporal backpropagation for spiking neural networks with one spike per neuron\" , published in the International Journal of Neural Systems by S. R. Kheradpisheh and T. Masquelier.*\n","\n","*The paper is availbale at:* https://www.worldscientific.com/doi/10.1142/S0129065720500276 \n","\n","**Important points:**\n","*   To enable GPU on Google CoLab, you should go to the Edit > Notebook Setting menue and set the Hardware Accelerator to GPU.\n","*   To work on MNIST, you should unzip the MNIST.zip and upload the folder on your Google Drive account.\n"]},{"cell_type":"code","metadata":{"id":"uvx78e27udh7","colab_type":"code","colab":{}},"source":["#CoLab settings\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import sys\n","sys.path.append('/content/gdrive/My Drive')\n","!pip install python-mnist\n","\n","# Imports\n","from __future__ import division\n","from mnist import MNIST\n","import numpy as np\n","import cupy as cp # You need to have a CUDA-enabled GPU to use this package!\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_EeGveguknc","colab_type":"code","colab":{}},"source":["#Parameter setting\n","thr = [100, 100]   #The threshold of hidden and output neurons\n","lr = [.2,.2]    #The learning rate of hidden and ouput neurons\n","lamda=[0.000001,0.000001]   # The regularization penalty for hidden and ouput neurons\n","b=[5,48]    #The upper bound of wight initializations for hidden and ouput neurons\n","a=[0,0]    #The lower bound of wight initializations for hidden and ouput neurons\n","Nepoch = 40    #The maximum number of training epochs\n","NumOfClasses = 10    #Number of classes\n","Nlayers = 2    #Number of layers\n","NhidenNeurons =400   #Number of hidden neurons\n","Dropout=[0,0] \n","tmax = 256   #Simulatin time\n","GrayLevels=255 #Image GrayLevels\n","gamma=3 #The gamma parameter in the relative target firing calculation\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj1LWIXkuscP","colab_type":"code","colab":{}},"source":["#General settings\n","loading=False   # Set it as True if you want to load a pretrained model\n","LoadFrom= \"/content/gdrive/My Drive/weights.npy\"  # The pretrained model\n","saving=False    # Set it as True if you want to save the trained model\n","best_perf=0\n","Nnrn = [NhidenNeurons, NumOfClasses]   # Number of neurons at hidden and output layers\n","cats=[4,1,0,7,9,2,3,5,8,6]   # Reordering the categories"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkiwnLYAuwdH","colab_type":"code","colab":{}},"source":["#General variables\n","images=[]  # To keep training images\n","labels=[]  # To keep training labels\n","images_test=[]  # To keep test images\n","labels_test=[]  # To keep test labels\n","W=[] #To hold the weights of hidden and output layers\n","firingTime=[] #To hold the firing times of hidden and output layers\n","Spikes=[] #To hold the spike trains of hidden and output layers\n","X=[] #To be used in converting firing times to spike trains\n","target = cp.zeros([NumOfClasses]) # To keep the target firing times of current image\n","FiringFrequency=[] # to count number of spikes each neuron emits during an epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXDFUNLnu5ce","colab_type":"code","colab":{}},"source":["#loading MNIST dataset\n","mndata = MNIST('/content/gdrive/My Drive//MNIST/')\n","# mndata.gz = False\n","\n","Images, Labels = mndata.load_training()\n","Images=np.array(Images)    \n","for i in range(len(Labels)):\n","    if Labels[i] in cats:\n","        images.append(np.floor((GrayLevels-Images[i].reshape(28,28))*tmax/GrayLevels).astype(int))\n","        labels.append(cats.index(Labels[i]))\n","  \n","Images, Labels = mndata.load_testing()\n","Images=np.array(Images)\n","for i in range(len(Labels)):\n","    if Labels[i] in cats:\n","        #images_test.append(TTT[i].reshape(28,28).astype(int))            \n","        images_test.append(np.floor((GrayLevels-Images[i].reshape(28,28))*tmax/GrayLevels).astype(int)) \n","        labels_test.append(cats.index(Labels[i]))\n","                        \n","del Images,Labels\n","\n","images = cp.asarray(images)\n","labels = cp.asarray(labels)\n","images_test = cp.asarray(images_test)\n","labels_test = cp.asarray(labels_test)    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQ1okDAlvBDb","colab_type":"code","colab":{}},"source":["#Building the model\n","layerSize=[[images[0].shape[0],images[0].shape[1]], [NhidenNeurons,1],[NumOfClasses,1]]    \n","x = cp.mgrid[0:layerSize[0][0],0:layerSize[0][1]]# To be used in converting raw image into a spike image\n","SpikeImage = cp.zeros((layerSize[0][0],layerSize[0][1], tmax+1)) # To keep spike image\n","\n","# Initializing the network\n","np.random.seed(0)\n","for layer in range(Nlayers):\n","    W.append(cp.asarray((b[layer] - a[layer]) * np.random.random_sample((Nnrn[layer], layerSize[layer][0],layerSize[layer][1])) + a[layer])) \n","    firingTime.append(cp.asarray(np.zeros(Nnrn[layer])))\n","    Spikes.append(cp.asarray(np.zeros((layerSize[layer+1][0],layerSize[layer+1][1],tmax+1))))\n","    X.append(cp.asarray(np.mgrid[0:layerSize[layer+1][0],0:layerSize[layer+1][1]]))\n","if loading:\n","  W=np.load(LoadFrom, allow_pickle=True)\n","\n","SpikeList=[SpikeImage]+Spikes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ogSqG-UTww-F","colab_type":"text"},"source":["**To evaluate the pretrained model you should skip the cell below and run the next cell**."]},{"cell_type":"code","metadata":{"id":"hwW46lALvPJm","colab_type":"code","colab":{}},"source":["# Start learning\n","for epoch in range(Nepoch):\n","    start_time = time.time()\n","    correct=cp.zeros(NumOfClasses)\n","    FiringFrequency=cp.zeros((NhidenNeurons))\n","\n","    # Start an epoch\n","    for iteration in range(len(images)): \n","        #converting input image into spiking image\n","        SpikeImage[:,:,:]=0\n","        SpikeImage[x[0],x[1],images[iteration]] = 1\n","\n","        #Feedforward path\n","        for layer in range(Nlayers):\n","            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1) # Computing the voltage\n","            Voltage[:,tmax]=thr[layer]+1 # Forcing the fake spike\n","            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1   # Findign the first threshold crossing  \n","            firingTime[layer][firingTime[layer]>tmax]=tmax # Forcing the fake spike\n","                \n","            Spikes[layer][:,:,:]=0   \n","            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1 #converting firing times to spikes\n","\n","        \n","        FiringFrequency =  FiringFrequency + (firingTime[0] < tmax) # FiringFrequency is used to find dead neurons\n","\n","        #Computing the relative target firing times\n","        winner=np.argmin(firingTime[Nlayers-1]) \n","        minFiring=min(firingTime[layer])\n","        if minFiring == tmax:          \n","            target[:]=minFiring\n","            target[labels[iteration]]=minFiring-gamma\n","            target=target.astype(int)\n","        else:\n","            target[:]=firingTime[layer][:]\n","            toChange=(firingTime[layer]-minFiring)<gamma\n","            target[toChange]=min(minFiring+gamma,tmax)\n","            target[labels[iteration]]=minFiring\n","          \n","\n","        #Backward path\n","        layer= Nlayers-1 # Output layer\n","\n","        delta_o=(target-firingTime[layer])/tmax # Error in the ouput layer\n","\n","        #Gradient normalization\n","        norm=cp.linalg.norm(delta_o)\n","        if (norm!=0):\n","            delta_o=delta_o/norm\n","            \n","        if Dropout[layer]>0:\n","                firingTime[layer][cp.asarray(np.random.permutation(Nnrn[layer])[:Dropout[layer]])]=tmax\n","        \n","        # Updating hidden-output weights\n","        hasFired_o=firingTime[layer-1]<firingTime[layer][:, cp.newaxis] # To find which hidden neurons has fired before the ouput neurons\n","        W[layer][:,:,0]-=(delta_o[:, cp.newaxis]*hasFired_o*lr[layer]) # Update hidden-ouput weights \n","        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n","\n","        # Backpropagating error to hidden neurons\n","        delta_h=(cp.multiply(delta_o[:, cp.newaxis]*hasFired_o, W[layer][:,:,0])).sum(axis=0) #Backpropagated errors from ouput layer to hidden layer\n","        \n","\n","        layer= Nlayers-2 # Hidden layer     \n","        \n","        #Gradient normalization\n","        norm=cp.linalg.norm(delta_h)\n","        if (norm!=0):\n","            delta_h=delta_h/norm\n","        # Updating input-hidden weights\n","        hasFired_h=images[iteration]<firingTime[layer][:, cp.newaxis, cp.newaxis] # To find which input neurons has fired before the hidden neurons\n","        W[layer]-=lr[layer]*delta_h[:, cp.newaxis, cp.newaxis]*hasFired_h # Update input-hidden weights \n","        W[layer]-=lr[layer]*lamda[layer]*W[layer] # Weight regularization\n","\n","    #Evaluating on test samples\n","    correct=0 \n","    for iteration in range(len(images_test)):        \n","        SpikeImage[:,:,:]=0\n","        SpikeImage[x[0],x[1],images_test[iteration]] = 1\n","        for layer in range(Nlayers):\n","            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n","            Voltage[:,tmax]=thr[layer]+1\n","            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n","            firingTime[layer][firingTime[layer]>tmax]=tmax\n","            Spikes[layer][:,:,:]=0   \n","            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n","        minFiringTime=firingTime[Nlayers-1].min()\n","        if minFiringTime==tmax:\n","            V=np.argmax(Voltage[:,tmax-3])\n","            if V==labels_test[iteration]:\n","              correct+=1\n","        else:\n","            if firingTime[layer][labels_test[iteration]]==minFiringTime:\n","                correct+=1           \n","    testPerf=correct/len(images_test)\n","   \n","   \n","    #Evaluating on train samples\n","    correct=0 \n","    for iteration in range(len(images)):        \n","        SpikeImage[:,:,:]=0\n","        SpikeImage[x[0],x[1],images[iteration]] = 1\n","        for layer in range(Nlayers):\n","            Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n","            Voltage[:,tmax]=thr[layer]+1\n","            firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n","            firingTime[layer][firingTime[layer]>tmax]=tmax      \n","            Spikes[layer][:,:,:]=0   \n","            Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1               \n","        minFiringTime=firingTime[Nlayers-1].min()\n","        if minFiringTime==tmax:\n","            V=np.argmax(Voltage[:,tmax-3])\n","            if V==labels[iteration]:\n","              correct+=1\n","        else:\n","            if firingTime[layer][labels[iteration]]==minFiringTime:\n","                correct+=1\n","    trainPerf=correct/len(images)  \n","\n","    \n","    print('epoch= ', epoch, 'Perf_train= ',trainPerf, 'Perf_test= ',testPerf)\n","    print(\"--- %s seconds ---\" % (time.time() - start_time))\n","        \n","    #To save the weights\n","    if saving:\n","      np.save(\"/content/gdrive/My Drive/weights\", W, allow_pickle=True)\n","      if testPerf>best_perf:\n","        np.save(\"/content/gdrive/My Drive/weights_best\", W, allow_pickle=True)\n","        best_perf=val\n","\n","    #To find and reset dead neurons    \n","    ResetCheck = FiringFrequency <0.001*len(images)    \n","    ToReset = [i for i in range(NhidenNeurons) if ResetCheck[i]]\n","    for i in ToReset:\n","         W[0][i]=cp.asarray((b[0] - a[0]) * np.random.random_sample((layerSize[0][0],layerSize[0][1])) + a[0]) #r\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFtyvkm_wmHs","colab_type":"text"},"source":["**To evaluate the pretrained model you can run the cell below.**"]},{"cell_type":"code","metadata":{"id":"MUjogm1bvxcb","colab_type":"code","colab":{}},"source":[" #Evaluating the pretrained model\n","LoadFrom= \"/content/gdrive/My Drive/weights_pretrained.npy\"  # The pretrained model\n","W=np.load(LoadFrom, allow_pickle=True)\n","\n","correct=0 \n","for iteration in range(len(images_test)):        \n","    SpikeImage[:,:,:]=0\n","    SpikeImage[x[0],x[1],images_test[iteration]] = 1\n","    for layer in range(Nlayers):\n","        Voltage=cp.cumsum(cp.tensordot(W[layer], SpikeList[layer]),1)\n","        Voltage[:,tmax]=thr[layer]+1\n","        firingTime[layer] = cp.argmax(Voltage>thr[layer],axis=1).astype(float)+1     \n","        firingTime[layer][firingTime[layer]>tmax]=tmax\n","        Spikes[layer][:,:,:]=0   \n","        Spikes[layer][X[layer][0],X[layer][1],firingTime[layer].reshape(Nnrn[layer],1).astype(int)]=1\n","    minFiringTime=firingTime[Nlayers-1].min()\n","    if minFiringTime==tmax:\n","        V=np.argmax(Voltage[:,tmax-3])\n","        if V==labels_test[iteration]:\n","          correct+=1\n","    else:\n","        if firingTime[layer][labels_test[iteration]]==minFiringTime:\n","            correct+=1           \n","testPerf=correct/len(images_test)\n","print('Perf_test= ',testPerf)"],"execution_count":0,"outputs":[]}]}
